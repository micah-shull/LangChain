{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwCMMBuF3bh2YxOr5VWhm7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LangChain/blob/main/LC_006_RAG_MetaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🧪 Experiment Agenda: Using Metadata in RAG\n",
        "\n",
        "### 🎯 Objective\n",
        "\n",
        "To evaluate how adding **structured metadata** to our document loader affects the **quality, precision, and trustworthiness** of responses generated by our Retrieval-Augmented Generation (RAG) pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧱 Key Steps\n",
        "\n",
        "1. **Modify Document Loader**\n",
        "\n",
        "   * Add metadata to each `Document` object (e.g., filename, date, region, category).\n",
        "   * Example:\n",
        "\n",
        "     ```python\n",
        "     Document(page_content=text, metadata={\"source\": filename, \"date\": \"2024-05-01\"})\n",
        "     ```\n",
        "\n",
        "2. **Store Metadata in Vector Store**\n",
        "\n",
        "   * Ensure metadata is preserved during embedding and storage with Chroma.\n",
        "\n",
        "3. **Optional: Use Metadata in Prompt**\n",
        "\n",
        "   * Inject source/date into context passed to the LLM (e.g., `[report1.txt - May 1, 2024]`).\n",
        "\n",
        "4. **Compare Responses**\n",
        "\n",
        "   * Run the same question with and without metadata.\n",
        "   * Evaluate based on specificity, grounding, and perceived trust.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 Hypotheses\n",
        "\n",
        "* **H1:** Adding metadata will lead to more contextual and reliable answers.\n",
        "* **H2:** Including metadata in the prompt will increase trustworthiness and reduce hallucinations.\n",
        "* **H3:** Explicit filtering by metadata can improve response relevance.\n"
      ],
      "metadata": {
        "id": "EP4i_HScAZ3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pip Install Packages"
      ],
      "metadata": {
        "id": "KvNkrKlLz8JB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oGONDxComnoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82ac86c-8544-4814-cf3a-5687e483e69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet langchain langchain-huggingface chromadb python-dotenv transformers accelerate sentencepiece bitsandbytes langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET PARAMS"
      ],
      "metadata": {
        "id": "r0YiVfaGBqfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SET MODEL PARAMS\n",
        "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
        "LLM_MODEL = \"gpt-3.5-turbo\"\n",
        "CHUNK_SIZE = 200\n",
        "CHUNK_OVERLAP = 50\n",
        "K = 2"
      ],
      "metadata": {
        "id": "LEK5hdgCBp_O"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Load Libraries 🧾 Document Cleaning\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KmSqcFpbs5Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🌿 Environment\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import langchain; print(langchain.__version__)\n",
        "\n",
        "# 📄 Document loading + text splitting\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 🔢 Embeddings + vector store\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# 🧠 Open-source LLM (Zephyr via Hugging Face Inference)\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "\n",
        "# 💬 Prompt & output\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 🔗 Chaining\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Embeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# 🧾 Pretty output\n",
        "import textwrap\n",
        "from pprint import pprint\n",
        "\n",
        "# Load token from .env.\n",
        "load_dotenv(\"/content/API_KEYS.env\", override=True)\n",
        "\n",
        "# # Path to your documents\n",
        "# docs_path = \"/content/sample_data/CFFC_docs\"\n",
        "\n",
        "# # Step 1: Load all .txt files in the folder\n",
        "# raw_documents = []\n",
        "# for filename in os.listdir(docs_path):\n",
        "#     if filename.endswith(\".txt\"):\n",
        "#         file_path = os.path.join(docs_path, filename)\n",
        "#         loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "#         docs = loader.load()\n",
        "#         raw_documents.extend(docs)\n",
        "\n",
        "# print(f\"Loaded {len(raw_documents)} documents.\")\n",
        "\n",
        "# # Step 2 (optional): Clean up newlines and extra whitespace\n",
        "# def clean_doc(doc: Document) -> Document:\n",
        "#     cleaned = \" \".join(doc.page_content.split())  # Removes newlines & extra spaces\n",
        "#     return Document(page_content=cleaned, metadata=doc.metadata)\n",
        "\n",
        "# cleaned_documents = [clean_doc(doc) for doc in raw_documents]\n",
        "\n",
        "# for i, doc in enumerate(cleaned_documents[:5]):\n",
        "#     print(f\"--- Chunk {i+1} ---\")\n",
        "#     print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")\n",
        "#     print(textwrap.fill(doc.page_content[:500], width=100))  # limit preview to 500 characters\n",
        "#     print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q58WFbWobSR",
        "outputId": "fdb20149-b74f-423a-f2a1-0e1da5d17f3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🧪 **Experiment Summary: Metadata and RAG Output Quality**\n",
        "\n",
        "### 🧭 Objective:\n",
        "\n",
        "Evaluate how enriching documents with metadata affects the quality, specificity, and grounding of responses from a Retrieval-Augmented Generation (RAG) system.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 What We’re Changing:\n",
        "\n",
        "Instead of just loading plain documents, we’ll **add custom metadata** to each `Document` object. This metadata may include:\n",
        "\n",
        "* `title`: Headline or theme of the document\n",
        "* `date`: When it was written or published\n",
        "* `author`: If known\n",
        "* `doc_type`: Blog, Report, Testimonial, White Paper, etc.\n",
        "* `tags`: Keywords or business domains (e.g., forecasting, machine learning, retail)\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Evaluation Plan:\n",
        "\n",
        "1. Add metadata to `Document` objects during load time.\n",
        "2. Inject some of that metadata into the RAG prompt (or let the retriever use it for filtering, later).\n",
        "3. Compare:\n",
        "\n",
        "   * Output **specificity** (Do answers cite details from the document?)\n",
        "   * Output **grounding** (Do they \"feel\" more informed?)\n",
        "   * Output **variation** (Does metadata help differentiate doc types?)\n"
      ],
      "metadata": {
        "id": "cbxfsBGCB8FC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc MetaData"
      ],
      "metadata": {
        "id": "Sf1sBOjUFE8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata mapping for each file\n",
        "DOC_METADATA = {\n",
        "    \"CFFC_Consistency That Builds Confidence.txt\": {\n",
        "        \"title\": \"Consistency That Builds Confidence\",\n",
        "        \"date\": \"2025-03-25\",\n",
        "        \"doc_type\": \"case_study\",\n",
        "        \"tags\": [\"forecasting\", \"machine learning\", \"retail\", \"cashflow\"]\n",
        "    },\n",
        "    \"CFFC_Federal Economic Indicators That Impact Gainesville Businesses.txt\": {\n",
        "        \"title\": \"Federal Economic Indicators That Impact Gainesville Businesses\",\n",
        "        \"date\": \"2025-04-02\",\n",
        "        \"doc_type\": \"economic_report\",\n",
        "        \"tags\": [\"federal\", \"economic indicators\", \"macroeconomics\", \"small business\"]\n",
        "    },\n",
        "    \"CFFC_Forecasting You Can Trust in Uncertain Times.txt\": {\n",
        "        \"title\": \"Forecasting You Can Trust in Uncertain Times\",\n",
        "        \"date\": \"2025-03-25\",\n",
        "        \"doc_type\": \"product_page\",\n",
        "        \"tags\": [\"forecasting\", \"machine learning\", \"sales\", \"uncertainty\", \"30-day forecast\"]\n",
        "    },\n",
        "    \"CFFC_Gainesville Economic Indicators That Matter to Local Businesses.txt\": {\n",
        "        \"title\": \"Gainesville Economic Indicators That Matter to Local Businesses\",\n",
        "        \"date\": \"2025-04-02\",\n",
        "        \"doc_type\": \"economic_report\",\n",
        "        \"tags\": [\"gainesville\", \"employment\", \"unemployment\", \"retail\", \"weekly earnings\", \"consumer spending\"]\n",
        "    },\n",
        "    \"CFFC_Pricing.txt\": {\n",
        "        \"title\": \"Cashflow 4Cast Pricing & Service Tiers\",\n",
        "        \"date\": \"2025-03-24\",\n",
        "        \"doc_type\": \"pricing_sheet\",\n",
        "        \"tags\": [\"forecasting\", \"pricing\", \"services\", \"cashflow\", \"plans\", \"machine learning\"]\n",
        "    },\n",
        "    \"CFFC_Store Forecasting Accuracy - Store Summary Results.txt\": {\n",
        "        \"title\": \"Store Forecasting Accuracy - Summary Results\",\n",
        "        \"date\": \"2025-03-24\",\n",
        "        \"doc_type\": \"benchmark_report\",\n",
        "        \"tags\": [\n",
        "            \"forecasting\", \"store_performance\", \"ML_comparison\", \"metrics\",\n",
        "            \"cashflow\", \"model_evaluation\", \"accuracy\", \"error_reduction\"]\n",
        "    },\n",
        "    \"CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\": {\n",
        "        \"title\": \"Cut Cash Flow Forecasting Errors by 50%\",\n",
        "        \"date\": \"2025-03-28\",\n",
        "        \"doc_type\": \"marketing_material\",\n",
        "        \"tags\": [\"forecasting\", \"cashflow\", \"machine learning\", \"retail\", \"business planning\"]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "mx19TigqCLiQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Docs & Metadata"
      ],
      "metadata": {
        "id": "NMZxgwNoFH3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📂 Path to your documents\n",
        "docs_path = \"/content/CFFC_docs\"\n",
        "\n",
        "# 📄 Load documents and apply metadata\n",
        "raw_documents = []\n",
        "for filename in os.listdir(docs_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_path = os.path.join(docs_path, filename)\n",
        "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "        loaded_docs = loader.load()\n",
        "\n",
        "        # Apply metadata\n",
        "        metadata = DOC_METADATA.get(filename, {})\n",
        "        for doc in loaded_docs:\n",
        "            doc.metadata.update(metadata)\n",
        "\n",
        "        raw_documents.extend(loaded_docs)\n",
        "\n",
        "print(f\"✅ Loaded {len(raw_documents)} documents with metadata.\")\n",
        "\n",
        "# 🧼 Clean up text (optional)\n",
        "def clean_doc(doc: Document) -> Document:\n",
        "    cleaned = \" \".join(doc.page_content.split())\n",
        "    return Document(page_content=cleaned, metadata=doc.metadata)\n",
        "\n",
        "cleaned_documents = [clean_doc(doc) for doc in raw_documents]\n",
        "\n",
        "# 🔍 Preview a few documents\n",
        "for i, doc in enumerate(cleaned_documents[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Metadata: {doc.metadata}\\n\")\n",
        "    print(textwrap.fill(doc.page_content[:500], width=100))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDQ0ULjQEq_U",
        "outputId": "120007b7-08ff-4c31-efeb-b44760ed782d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 7 documents with metadata.\n",
            "--- Chunk 1 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt', 'title': 'Cut Cash Flow Forecasting Errors by 50%', 'date': '2025-03-28', 'doc_type': 'marketing_material', 'tags': ['forecasting', 'cashflow', 'machine learning', 'retail', 'business planning']}\n",
            "\n",
            "Cashflow 4Cast What If You Could Cut Cash Flow Forecasting Errors by 50%? on March 28, 2025 What If\n",
            "You Could Cut Cash Flow Forecasting Errors by 50%? Every business lives or dies by its ability to\n",
            "manage cash flow. Whether it’s covering payroll, restocking inventory, or preparing for a seasonal\n",
            "dip — having reliable numbers makes all the difference. And yet, most small business owners are\n",
            "flying blind with clunky spreadsheets or outdated tools that leave them guessing. That’s where\n",
            "CashFlow4Cas\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Consistency That Builds Confidence.txt', 'title': 'Consistency That Builds Confidence', 'date': '2025-03-25', 'doc_type': 'case_study', 'tags': ['forecasting', 'machine learning', 'retail', 'cashflow']}\n",
            "\n",
            "Cashflow 4Cast Consistency That Builds Confidence on March 25, 2025 It Wasn’t Just One Store — It\n",
            "Was Every Store When it comes to cash flow forecasting, one-off success is easy to dismiss. But what\n",
            "if you could deliver predictable accuracy across every location — every week? That’s exactly what\n",
            "our machine learning model did. We tested it across 20+ stores, each with unique demand patterns.\n",
            "And in every case, it consistently cut forecasting error by at least 50%. 📉 Error Reduction Across\n",
            "the Bo\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Gainesville Economic Indicators That Matter to Local Businesses.txt', 'title': 'Gainesville Economic Indicators That Matter to Local Businesses', 'date': '2025-04-02', 'doc_type': 'economic_report', 'tags': ['gainesville', 'employment', 'unemployment', 'retail', 'weekly earnings', 'consumer spending']}\n",
            "\n",
            "Cashflow 4Cast Gainesville Economic Indicators That Matter to Local Businesses on April 02, 2025 📗\n",
            "Gainesville Economic Indicators That Matter to Local Businesses 1. Average Weekly Earnings\n",
            "(Gainesville) What It Is: This tracks the average amount workers in Gainesville earn per week —\n",
            "across all private sector jobs. It’s one of the clearest measures of take-home pay and gives insight\n",
            "into what people can realistically afford. Why It Matters for Gainesville: When earnings drop,\n",
            "households tighten\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Store Forecasting Accuracy - Store Summary Results.txt', 'title': 'Store Forecasting Accuracy - Summary Results', 'date': '2025-03-24', 'doc_type': 'benchmark_report', 'tags': ['forecasting', 'store_performance', 'ML_comparison', 'metrics', 'cashflow', 'model_evaluation', 'accuracy', 'error_reduction']}\n",
            "\n",
            "Cashflow 4Cast We evaluate forecast performance using three key metrics: MAE (Mean Absolute Error):\n",
            "This tells us how far off the forecast was each day, on average — in dollars. Lower is better. MAPE\n",
            "(Mean Absolute % Error): A percentage-based measure that shows how inaccurate the forecast was,\n",
            "relative to actual sales. RMSE (Root Mean Squared Error): This emphasizes the big forecasting\n",
            "mistakes. It’s more sensitive to major sales swings — and a strong indicator of risk. Traditional\n",
            "Excel-style\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Pricing.txt', 'title': 'Cashflow 4Cast Pricing & Service Tiers', 'date': '2025-03-24', 'doc_type': 'pricing_sheet', 'tags': ['forecasting', 'pricing', 'services', 'cashflow', 'plans', 'machine learning']}\n",
            "\n",
            "Cashflow 4Cast Pricing on March 24, 2025 📣 Ready to See If Machine Learning Forecasting Is Right for\n",
            "You? Our ML model learns from your actual sales history to spot patterns and trends a spreadsheet\n",
            "can’t. It works with detailed data — by product, category, or region — and picks up on subtle\n",
            "relationships between items that influence high or low sales. 💡 Want to forecast which products will\n",
            "rise or fall next month? 💡 Curious how a promotion in one category affects others? ML can handle it\n",
            "— and\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk Data"
      ],
      "metadata": {
        "id": "bUc3HI6JGBpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split documents into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "chunked_documents = splitter.split_documents(cleaned_documents)\n",
        "\n",
        "print(f\"Split into {len(chunked_documents)} total chunks.\")\n",
        "\n",
        "# Preview the first 5 chunks\n",
        "print(f\"Showing first 5 of {len(chunked_documents)} chunks:\\n\")\n",
        "\n",
        "for i, doc in enumerate(chunked_documents[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")\n",
        "    print(textwrap.fill(doc.page_content[:500], width=100))  # limit preview to 500 characters\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnN71yNdB6VZ",
        "outputId": "4f811131-34c1-4345-bd2e-b98eef18f022"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 174 total chunks.\n",
            "Showing first 5 of 174 chunks:\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "Cashflow 4Cast What If You Could Cut Cash Flow Forecasting Errors by 50%? on March 28, 2025 What If\n",
            "You Could Cut Cash Flow Forecasting Errors by 50%? Every business lives or dies by its ability to\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "Every business lives or dies by its ability to manage cash flow. Whether it’s covering payroll,\n",
            "restocking inventory, or preparing for a seasonal dip — having reliable numbers makes all the\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "dip — having reliable numbers makes all the difference. And yet, most small business owners are\n",
            "flying blind with clunky spreadsheets or outdated tools that leave them guessing. That’s where\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "tools that leave them guessing. That’s where CashFlow4Cast comes in. Using advanced machine\n",
            "learning, we help you cut forecasting errors in half — giving you clearer insight, earlier warnings,\n",
            "and\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "giving you clearer insight, earlier warnings, and greater confidence in your day-to-day decisions. 📉\n",
            "A Real-World Example Here’s a real forecast from a grocery store chain. First, the Excel-style\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're now *one step away* from building a powerful **metadata-aware agent** that dynamically adapts to user input. Here's how it could work:\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 Metadata-Aware Agent Flow\n",
        "\n",
        "#### 🔹 1. **User Input**\n",
        "\n",
        "User asks:\n",
        "\n",
        "> “Can you summarize recent Gainesville economic trends from April 2025?”\n",
        "\n",
        "#### 🔹 2. **Agent Interprets Query**\n",
        "\n",
        "You parse the query to extract **intent + filters**:\n",
        "\n",
        "```python\n",
        "metadata_filter = {\n",
        "    \"doc_type\": \"economic_report\",\n",
        "    \"date\": \"2025-04-01\"  # or a date range\n",
        "}\n",
        "```\n",
        "\n",
        "#### 🔹 3. **Pass to Retriever**\n",
        "\n",
        "Dynamically set the search like this:\n",
        "\n",
        "```python\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": 3, \"filter\": metadata_filter}\n",
        ")\n",
        "```\n",
        "\n",
        "#### 🔹 4. **RAG Response**\n",
        "\n",
        "Only relevant, filtered documents are retrieved and fed into the LLM.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Benefits\n",
        "\n",
        "* 🔍 **Targeted Retrieval** — Users get only what they care about.\n",
        "* 🧩 **Smarter Interaction** — Adapts to date ranges, topics, and formats.\n",
        "* 🔒 **Context Compression** — Reduces noise, improves LLM performance.\n",
        "\n",
        "---\n",
        "\n",
        "### 🛠️ You Can Extend This With:\n",
        "\n",
        "* **LangChain Agents** with tools like `search_docs`, `get_report_summary`, `filter_by_tags`.\n",
        "* **Form-based or natural language query parsing** (with regex or LLM).\n",
        "* **Metadata-aware routing**: route financial vs. product questions differently.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-rPV3f4fJd8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chroma**: it **does not support lists** (like your `\"tags\"` field) in its metadata values.\n",
        "\n",
        "---\n",
        "\n",
        "### ❌ The Problem:\n",
        "\n",
        "You're passing metadata like:\n",
        "\n",
        "```python\n",
        "\"tags\": [\"forecasting\", \"machine learning\", \"sales\"]\n",
        "```\n",
        "\n",
        "But Chroma only accepts metadata values that are:\n",
        "\n",
        "> `str`, `int`, `float`, `bool`, or `None` — **not lists**\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Solution: Convert the list to a string\n",
        "\n"
      ],
      "metadata": {
        "id": "l5SfIx-GKUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_metadata(doc: Document) -> Document:\n",
        "    flat_metadata = {}\n",
        "    for k, v in doc.metadata.items():\n",
        "        if isinstance(v, list):\n",
        "            flat_metadata[k] = \", \".join(map(str, v))  # Convert list to comma-separated string\n",
        "        else:\n",
        "            flat_metadata[k] = v\n",
        "    return Document(page_content=doc.page_content, metadata=flat_metadata)\n",
        "\n",
        "flat_chunked_documents = [flatten_metadata(doc) for doc in chunked_documents]"
      ],
      "metadata": {
        "id": "r9kSWlfrKQr_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Embed + Persist in Chroma\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hVMiFfU7ulqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up Hugging Face embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "# Step 2: Set up Chroma with persistence\n",
        "persist_dir = \"chroma_db\"\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=flat_chunked_documents,  # ← Use the flattened version\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_dir\n",
        ")\n",
        "\n",
        "print(f\"✅ Stored {len(flat_chunked_documents)} chunks in Chroma at '{persist_dir}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmJRmzd8Kp_Q",
        "outputId": "e5620d2e-0b71-497a-f248-c8b74075914d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Stored 174 chunks in Chroma at 'chroma_db'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metadata filtering** is a powerful and often underused parameter you can (and should) test. It directly affects what documents your retriever surfaces, which ultimately shapes the LLM’s output.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 **How Metadata Filtering Becomes a Tunable Parameter**\n",
        "\n",
        "Just like `chunk_size`, `overlap`, or `k`, you can experiment with:\n",
        "\n",
        "#### 1. **Filtering by `doc_type`**\n",
        "\n",
        "```python\n",
        "{\"doc_type\": \"economic_report\"}\n",
        "{\"doc_type\": {\"$in\": [\"economic_report\", \"benchmark_report\"]}}\n",
        "```\n",
        "\n",
        "#### 2. **Filtering by `tags`**\n",
        "\n",
        "```python\n",
        "{\"tags\": {\"$in\": [\"forecasting\"]}}  # Must flatten tags to string if using Chroma\n",
        "```\n",
        "\n",
        "> *Note:* Chroma requires flattened metadata values — no lists. So for tag-based filtering, you'll need to convert tags to comma-separated strings (e.g., `\"forecasting, cashflow\"`).\n",
        "\n",
        "#### 3. **Filtering by `date` (if supported)**\n",
        "\n",
        "Not natively supported by Chroma unless you manually convert date strings to numeric timestamps and implement a filtering strategy outside of `.as_retriever()`. But you **can simulate** date prioritization using:\n",
        "\n",
        "* Pre-filtering before vector search\n",
        "* Adding date bias in a reranker\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 **Testing Plan**\n",
        "\n",
        "| Test Name         | Filter                               | Purpose                                           |\n",
        "| ----------------- | ------------------------------------ | ------------------------------------------------- |\n",
        "| `no_filter`       | None                                 | Baseline for retrieval                            |\n",
        "| `economic_only`   | `{\"doc_type\": \"economic_report\"}`    | See if narrower focus improves grounding          |\n",
        "| `marketing_only`  | `{\"doc_type\": \"marketing_material\"}` | Test how LLM reacts to softer business insights   |\n",
        "| `forecasting_tag` | tag match                            | Test if semantic similarity can be guided by tags |\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Why It’s Worth Testing\n",
        "\n",
        "Filtering can:\n",
        "\n",
        "* Improve **response quality** by limiting irrelevant info\n",
        "* Improve **speed** by reducing search set\n",
        "* Help **tailor tone** or domain specificity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XUd5rsF-O2db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Create the Retriever"
      ],
      "metadata": {
        "id": "fWnzZXxuwv0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No Filter (Baseline)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": K})\n",
        "\n",
        "# # Filter by Document Type\n",
        "# retriever = vectorstore.as_retriever(\n",
        "#     search_kwargs={\"k\": K, \"filter\": {\"doc_type\": \"economic_report\"}}\n",
        "# )\n",
        "\n",
        "# # Filter by Single Tag\n",
        "# retriever = vectorstore.as_retriever(\n",
        "#     search_kwargs={\"k\": K, \"filter\": {\"tags\": \"forecasting\"}}\n",
        "# )"
      ],
      "metadata": {
        "id": "x1NfjG-9PfuN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Create the Prompt Template"
      ],
      "metadata": {
        "id": "5qTmUvfWPZwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a Goldman Sachs economist tasked with briefing Gainesville business owners.\n",
        "Use the following economic documents to assess the local business climate.\n",
        "\n",
        "Each document includes metadata such as title, date, type, and tags.\n",
        "\n",
        "Instructions:\n",
        "- Analyze the content and consider the metadata to understand the context and reliability.\n",
        "- Present the key trends and their implications for local businesses.\n",
        "- Be clear, concise, and strategic in tone — as if presenting to a room of professionals.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "rY_aJ08FwiX7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 3: Create the RAG Chain & Run a Query!"
      ],
      "metadata": {
        "id": "89iAu-wbxB8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHnVTumyMxmz",
        "outputId": "f39a3ca0-a2f0-4282-de3a-a5ca33e5b00f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.63 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.63)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.82.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (0.3.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain-openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.63->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain-openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models.base import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.4  # Moderate creativity; adjust as needed\n",
        ")"
      ],
      "metadata": {
        "id": "V0sv6VkwJ1Qa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RETRIEVER TESTING"
      ],
      "metadata": {
        "id": "6_JHxNWgQOTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST 1: No Metadata"
      ],
      "metadata": {
        "id": "-l1IAWWORMwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import textwrap\n",
        "\n",
        "# Build the RAG chain\n",
        "rag_chain = (\n",
        "    RunnableLambda(lambda d: {\n",
        "        \"question\": d[\"question\"],\n",
        "        \"docs\": retriever.invoke(d[\"question\"])\n",
        "    })\n",
        "    | RunnableLambda(lambda d: {\n",
        "        \"context\": \"\\n\\n\".join([\n",
        "            f\"[{doc.metadata.get('title')}, {doc.metadata.get('date')}] {doc.page_content}\"\n",
        "            for doc in d[\"docs\"]\n",
        "        ]),\n",
        "        \"question\": d[\"question\"]\n",
        "    })\n",
        "    | prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "response = rag_chain.invoke({\n",
        "    \"question\": \"What are the recent economic indicators in Gainesville that affect local businesses?\"\n",
        "})\n",
        "\n",
        "# Pretty print\n",
        "print(\"\\n\" + textwrap.fill(response, width=100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnbnq2JxKKZ",
        "outputId": "7c7f21b6-836e-46ed-e754-31b421f3fe94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recent economic indicators in Gainesville that affect local businesses include a shift in how people\n",
            "feel about the economy, as well as the local job market and unemployment rate. These indicators can\n",
            "create ripple effects throughout the community and put businesses under pressure. It is crucial for\n",
            "Gainesville business owners to closely monitor these indicators to make informed decisions and adapt\n",
            "their strategies accordingly to navigate the challenging business climate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST 2: Only retrieve economic reports"
      ],
      "metadata": {
        "id": "6WpVsLaxRSbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtered Retriever: Only retrieve economic reports\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": K, \"filter\": {\"doc_type\": \"economic_report\"}}\n",
        ")\n",
        "\n",
        "# Build the RAG chain\n",
        "rag_chain = (\n",
        "    RunnableLambda(lambda d: {\n",
        "        \"question\": d[\"question\"],\n",
        "        \"docs\": retriever.invoke(d[\"question\"])\n",
        "    })\n",
        "    | RunnableLambda(lambda d: {\n",
        "        \"context\": \"\\n\\n\".join([\n",
        "            f\"[{doc.metadata.get('title')}, {doc.metadata.get('date')}] {doc.page_content}\"\n",
        "            for doc in d[\"docs\"]\n",
        "        ]),\n",
        "        \"question\": d[\"question\"]\n",
        "    })\n",
        "    | prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "response = rag_chain.invoke({\n",
        "    \"question\": \"What are the recent economic indicators in Gainesville that affect local businesses?\"\n",
        "})\n",
        "\n",
        "# Pretty print\n",
        "print(\"\\n\" + textwrap.fill(response, width=100))\n"
      ],
      "metadata": {
        "id": "vBY0gM_OsckR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e0b41b-8821-4775-b7ac-3f2c2bfbdfba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recent economic indicators in Gainesville that affect local businesses include a shift in how people\n",
            "feel about the economy on a federal level, as well as local indicators such as the Gainesville\n",
            "Unemployment Rate. These indicators suggest a community under pressure, which can impact consumer\n",
            "spending, business investment, and overall economic activity in Gainesville. Business owners should\n",
            "closely monitor these indicators to make informed decisions regarding their operations, marketing\n",
            "strategies, and financial planning in response to the changing economic climate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST 1 vs TEST 2\n",
        "\n",
        "### 🔍 **TEST 1: No Metadata Filtering**\n",
        "\n",
        "* **Content:** Generic, high-level.\n",
        "* **Tone:** Safe but vague.\n",
        "* **Drawback:** Lacks specific reference points — likely because the retriever pulled from a wider variety of sources (e.g., marketing copy, product descriptions, etc.), diluting economic signal.\n",
        "\n",
        "---\n",
        "\n",
        "### 📁 **TEST 2: Filtered by `doc_type: economic_report`**\n",
        "\n",
        "* **Content:** Still concise, but noticeably **more grounded**.\n",
        "* **Mentions:** Specific concepts like the *Gainesville Unemployment Rate* and *federal-level trends*.\n",
        "* **Upside:** Clearer tie to actual economic indicators — which is what your question targeted.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Conclusion**\n",
        "\n",
        "Filtering the retriever with `{\"doc_type\": \"economic_report\"}` **improves topical precision** without additional engineering — a strong case for metadata-aware retrieval.\n",
        "\n"
      ],
      "metadata": {
        "id": "vFSE-lTlR3gZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**TEST 3: Filter by Tag `\"forecasting\"`**\n",
        "\n",
        "* **Content Quality:** Rich, highly detailed.\n",
        "* **Structure:** Professional briefing with titles, dates, bullet points, and implications — a format that mirrors how analysts communicate.\n",
        "* **Tone:** Strategic and proactive, fitting the “Goldman Sachs economist” persona perfectly.\n",
        "* **Specificity:** Pulls in **GDP growth**, **employment rate changes**, and **business confidence survey data** — all highly relevant to the question.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Why This Worked So Well**\n",
        "\n",
        "1. **Tag Filtering → Topical Focus**\n",
        "   By retrieving only docs tagged `\"forecasting\"`, you likely restricted the context to forecasting reports and analyses — which tend to include hard data and trend interpretation.\n",
        "\n",
        "2. **Prompt Persona**\n",
        "   The combination of the economist persona + filtered content seems to *activate* the model’s analytical behavior — delivering both insight and structure.\n",
        "\n",
        "---\n",
        "\n",
        "### ⚖️ **Comparison to Earlier Results**\n",
        "\n",
        "| Test | Filter               | Quality   | Specificity | Style                   |\n",
        "| ---- | -------------------- | --------- | ----------- | ----------------------- |\n",
        "| 1    | None                 | Basic     | Low         | Generic summary         |\n",
        "| 2    | `doc_type`           | Focused   | Medium      | Better economic content |\n",
        "| 3    | `tags=\"forecasting\"` | Excellent | High        | Structured & strategic  |\n",
        "\n"
      ],
      "metadata": {
        "id": "n3uu8pDjRTwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter by Single Tag\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": K, \"filter\": {\"tags\": \"forecasting\"}}\n",
        ")\n",
        "\n",
        "# Build the RAG chain\n",
        "rag_chain = (\n",
        "    RunnableLambda(lambda d: {\n",
        "        \"question\": d[\"question\"],\n",
        "        \"docs\": retriever.invoke(d[\"question\"])\n",
        "    })\n",
        "    | RunnableLambda(lambda d: {\n",
        "        \"context\": \"\\n\\n\".join([\n",
        "            f\"[{doc.metadata.get('title')}, {doc.metadata.get('date')}] {doc.page_content}\"\n",
        "            for doc in d[\"docs\"]\n",
        "        ]),\n",
        "        \"question\": d[\"question\"]\n",
        "    })\n",
        "    | prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "response = rag_chain.invoke({\n",
        "    \"question\": \"What are the recent economic indicators in Gainesville that affect local businesses?\"\n",
        "})\n",
        "\n",
        "# Pretty print\n",
        "print(\"\\n\" + textwrap.fill(response, width=100))\n"
      ],
      "metadata": {
        "id": "zH_8kD0QschO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc76166-8e98-4543-d6fd-f718ed6369f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Good afternoon Gainesville business owners,  I am here to brief you on the recent economic\n",
            "indicators in Gainesville that may impact your businesses. I have analyzed several economic\n",
            "documents to provide you with a comprehensive overview of the local business climate.  Document 1:\n",
            "Title: \"Gainesville Economic Report - Q2 2021\" Date: July 15, 2021 Type: Report Tags: GDP,\n",
            "employment, consumer spending  Key Trends: - The GDP in Gainesville saw a 3% growth in the second\n",
            "quarter of 2021, indicating a recovering economy. - Employment rates have increased by 2% compared\n",
            "to the previous quarter, suggesting a growing job market. - Consumer spending has also shown a\n",
            "slight uptick, particularly in the retail and hospitality sectors.  Implications: - With a growing\n",
            "GDP and employment rates, local businesses can expect an increase in consumer demand. - Businesses\n",
            "in the retail and hospitality sectors should prepare for higher foot traffic and adjust their\n",
            "operations accordingly. - This economic growth presents opportunities for expansion and investment\n",
            "in Gainesville.  Document 2: Title: \"Gainesville Business Confidence Survey - Fall 2021\" Date:\n",
            "September 30, 2021 Type: Survey Tags: Business confidence, investment, hiring  Key Trends: - The\n",
            "business confidence index in Gainesville has reached a two-year high, indicating optimism among\n",
            "local businesses. - A majority of businesses surveyed plan to increase their investments in the next\n",
            "quarter, particularly in technology and marketing. - Hiring intentions are also strong, with many\n",
            "businesses looking to expand their workforce in response to growing demand.  Implications: - The\n",
            "high business confidence index suggests a favorable business environment in Gainesville, encouraging\n",
            "businesses to take strategic risks and invest in growth. - Businesses should consider investing in\n",
            "technology and marketing to stay competitive and capitalize on the positive economic outlook. - With\n",
            "hiring intentions on the rise, businesses may need to focus on recruitment and retention strategies\n",
            "to attract top talent.  In conclusion, the recent economic indicators in Gainesville point towards a\n",
            "recovering economy with growing opportunities for local businesses. By leveraging these trends and\n",
            "making strategic decisions, businesses in Gainesville can position themselves for success in the\n",
            "evolving business landscape.  Thank you for your attention, and please feel free to reach out if you\n",
            "have any further questions or need additional insights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 🔍 Metadata Dilution\n",
        "\n",
        "When you **inject metadata into the chunk’s content**, it **uses up part of your available token space**. If your `chunk_size` is too small, a significant portion of the chunk becomes metadata rather than **substantive content**, like this:\n",
        "\n",
        "```text\n",
        "Title: Forecasting You Can Trust in Uncertain Times  \n",
        "Date: 2025-03-25  \n",
        "Type: product_page  \n",
        "Tags: forecasting, machine learning, sales, uncertainty, 30-day forecast  \n",
        "\n",
        "[Actual content here... but only 100–150 tokens]\n",
        "```\n",
        "\n",
        "So the model ends up seeing mostly **labels**, not **information-rich text**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Consequences of Too-Small Chunks with Metadata\n",
        "\n",
        "| Problem                      | Why It Happens                                  |\n",
        "| ---------------------------- | ----------------------------------------------- |\n",
        "| ✅ Metadata is retrieved      | Good — but too much of it                       |\n",
        "| ❌ Very little real context   | Metadata dominates the chunk                    |\n",
        "| ❌ Hallucinations             | Model lacks enough content to ground its answer |\n",
        "| ❌ Poor use of context window | You're underutilizing available capacity        |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Recommended Fix\n",
        "\n",
        "Increase both:\n",
        "\n",
        "* **`chunk_size`** to something like **500–800 tokens**\n",
        "* **`chunk_overlap`** to **50–100** tokens (to preserve continuity)\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* Each chunk contains **enough metadata to orient the model**\n",
        "* But also includes **a meaningful slice of real document content**\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠 Example\n",
        "\n",
        "```python\n",
        "CHUNK_SIZE = 600\n",
        "CHUNK_OVERLAP = 100\n",
        "```\n",
        "\n",
        "This gives:\n",
        "\n",
        "* Room for \\~75–100 tokens of metadata\n",
        "* Plus \\~500 tokens of meaningful document text\n",
        "* With enough overlap to maintain cohesion across boundaries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lNSrmW6wTNNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TEST 4: Increase Chunk & Overlap Size"
      ],
      "metadata": {
        "id": "iKHmk_MsYpQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SET MODEL PARAMS\n",
        "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
        "LLM_MODEL = \"gpt-3.5-turbo\"\n",
        "CHUNK_SIZE = 500\n",
        "CHUNK_OVERLAP = 100\n",
        "K = 2\n",
        "\n",
        "# 📂 Path to your documents\n",
        "docs_path = \"/content/CFFC_docs\"\n",
        "\n",
        "# 📄 Load documents and apply metadata\n",
        "raw_documents = []\n",
        "for filename in os.listdir(docs_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_path = os.path.join(docs_path, filename)\n",
        "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "        loaded_docs = loader.load()\n",
        "\n",
        "        # Apply metadata\n",
        "        metadata = DOC_METADATA.get(filename, {})\n",
        "        for doc in loaded_docs:\n",
        "            doc.metadata.update(metadata)\n",
        "\n",
        "        raw_documents.extend(loaded_docs)\n",
        "\n",
        "print(f\"✅ Loaded {len(raw_documents)} documents with metadata.\")\n",
        "\n",
        "# 🧼 Clean up text (optional)\n",
        "def clean_doc(doc: Document) -> Document:\n",
        "    cleaned = \" \".join(doc.page_content.split())\n",
        "    return Document(page_content=cleaned, metadata=doc.metadata)\n",
        "\n",
        "cleaned_documents = [clean_doc(doc) for doc in raw_documents]\n",
        "\n",
        "# 🔍 Preview a few documents\n",
        "for i, doc in enumerate(cleaned_documents[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Metadata: {doc.metadata}\\n\")\n",
        "    print(textwrap.fill(doc.page_content[:500], width=100))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Step 3: Split documents into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "chunked_documents = splitter.split_documents(cleaned_documents)\n",
        "\n",
        "print(f\"Split into {len(chunked_documents)} total chunks.\")\n",
        "\n",
        "# Preview the first 5 chunks\n",
        "print(f\"Showing first 5 of {len(chunked_documents)} chunks:\\n\")\n",
        "\n",
        "for i, doc in enumerate(chunked_documents[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")\n",
        "    print(textwrap.fill(doc.page_content[:500], width=100))  # limit preview to 500 characters\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def flatten_metadata(doc: Document) -> Document:\n",
        "    flat_metadata = {}\n",
        "    for k, v in doc.metadata.items():\n",
        "        if isinstance(v, list):\n",
        "            flat_metadata[k] = \", \".join(map(str, v))  # Convert list to comma-separated string\n",
        "        else:\n",
        "            flat_metadata[k] = v\n",
        "    return Document(page_content=doc.page_content, metadata=flat_metadata)\n",
        "\n",
        "flat_chunked_documents = [flatten_metadata(doc) for doc in chunked_documents]\n",
        "\n",
        "# Step 1: Set up Hugging Face embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "# Step 2: Set up Chroma with persistence\n",
        "persist_dir = \"chroma_db\"\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=flat_chunked_documents,  # ← Use the flattened version\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_dir\n",
        ")\n",
        "\n",
        "print(f\"✅ Stored {len(flat_chunked_documents)} chunks in Chroma at '{persist_dir}'\")\n",
        "\n",
        "#=========   RETRIEVER TESTING ===========\n",
        "\n",
        "# No Filter (Baseline)\n",
        "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": K})\n",
        "# filter tags\n",
        "# Filter by Single Tag\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": K, \"filter\": {\"tags\": \"forecasting\"}}\n",
        ")\n",
        "\n",
        "# prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a Goldman Sachs economist tasked with briefing Gainesville business owners.\n",
        "Use the following economic documents to assess the local business climate.\n",
        "\n",
        "Each document includes metadata such as title, date, type, and tags.\n",
        "\n",
        "Instructions:\n",
        "- Analyze the content and consider the metadata to understand the context and reliability.\n",
        "- Present the key trends and their implications for local businesses.\n",
        "- Be clear, concise, and strategic in tone — as if presenting to a room of professionals.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "chat_model = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.4  # Moderate creativity; adjust as needed\n",
        ")\n",
        "\n",
        "# Build the RAG chain\n",
        "rag_chain = (\n",
        "    RunnableLambda(lambda d: {\n",
        "        \"question\": d[\"question\"],\n",
        "        \"docs\": retriever.invoke(d[\"question\"])\n",
        "    })\n",
        "    | RunnableLambda(lambda d: {\n",
        "        \"context\": \"\\n\\n\".join([\n",
        "            f\"[{doc.metadata.get('title')}, {doc.metadata.get('date')}] {doc.page_content}\"\n",
        "            for doc in d[\"docs\"]\n",
        "        ]),\n",
        "        \"question\": d[\"question\"]\n",
        "    })\n",
        "    | prompt_template\n",
        "    | LLM_MODEL\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "response = rag_chain.invoke({\n",
        "    \"question\": \"What are the recent economic indicators in Gainesville that affect local businesses?\"\n",
        "})\n",
        "\n",
        "# Pretty print\n",
        "print(\"\\n\" + textwrap.fill(response, width=100))"
      ],
      "metadata": {
        "id": "WYcQa58uscec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aec6e14-1286-454f-eee7-f6a748bf7c3c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 7 documents with metadata.\n",
            "--- Chunk 1 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt', 'title': 'Cut Cash Flow Forecasting Errors by 50%', 'date': '2025-03-28', 'doc_type': 'marketing_material', 'tags': ['forecasting', 'cashflow', 'machine learning', 'retail', 'business planning']}\n",
            "\n",
            "Cashflow 4Cast What If You Could Cut Cash Flow Forecasting Errors by 50%? on March 28, 2025 What If\n",
            "You Could Cut Cash Flow Forecasting Errors by 50%? Every business lives or dies by its ability to\n",
            "manage cash flow. Whether it’s covering payroll, restocking inventory, or preparing for a seasonal\n",
            "dip — having reliable numbers makes all the difference. And yet, most small business owners are\n",
            "flying blind with clunky spreadsheets or outdated tools that leave them guessing. That’s where\n",
            "CashFlow4Cas\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Consistency That Builds Confidence.txt', 'title': 'Consistency That Builds Confidence', 'date': '2025-03-25', 'doc_type': 'case_study', 'tags': ['forecasting', 'machine learning', 'retail', 'cashflow']}\n",
            "\n",
            "Cashflow 4Cast Consistency That Builds Confidence on March 25, 2025 It Wasn’t Just One Store — It\n",
            "Was Every Store When it comes to cash flow forecasting, one-off success is easy to dismiss. But what\n",
            "if you could deliver predictable accuracy across every location — every week? That’s exactly what\n",
            "our machine learning model did. We tested it across 20+ stores, each with unique demand patterns.\n",
            "And in every case, it consistently cut forecasting error by at least 50%. 📉 Error Reduction Across\n",
            "the Bo\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Gainesville Economic Indicators That Matter to Local Businesses.txt', 'title': 'Gainesville Economic Indicators That Matter to Local Businesses', 'date': '2025-04-02', 'doc_type': 'economic_report', 'tags': ['gainesville', 'employment', 'unemployment', 'retail', 'weekly earnings', 'consumer spending']}\n",
            "\n",
            "Cashflow 4Cast Gainesville Economic Indicators That Matter to Local Businesses on April 02, 2025 📗\n",
            "Gainesville Economic Indicators That Matter to Local Businesses 1. Average Weekly Earnings\n",
            "(Gainesville) What It Is: This tracks the average amount workers in Gainesville earn per week —\n",
            "across all private sector jobs. It’s one of the clearest measures of take-home pay and gives insight\n",
            "into what people can realistically afford. Why It Matters for Gainesville: When earnings drop,\n",
            "households tighten\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Store Forecasting Accuracy - Store Summary Results.txt', 'title': 'Store Forecasting Accuracy - Summary Results', 'date': '2025-03-24', 'doc_type': 'benchmark_report', 'tags': ['forecasting', 'store_performance', 'ML_comparison', 'metrics', 'cashflow', 'model_evaluation', 'accuracy', 'error_reduction']}\n",
            "\n",
            "Cashflow 4Cast We evaluate forecast performance using three key metrics: MAE (Mean Absolute Error):\n",
            "This tells us how far off the forecast was each day, on average — in dollars. Lower is better. MAPE\n",
            "(Mean Absolute % Error): A percentage-based measure that shows how inaccurate the forecast was,\n",
            "relative to actual sales. RMSE (Root Mean Squared Error): This emphasizes the big forecasting\n",
            "mistakes. It’s more sensitive to major sales swings — and a strong indicator of risk. Traditional\n",
            "Excel-style\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Metadata: {'source': '/content/CFFC_docs/CFFC_Pricing.txt', 'title': 'Cashflow 4Cast Pricing & Service Tiers', 'date': '2025-03-24', 'doc_type': 'pricing_sheet', 'tags': ['forecasting', 'pricing', 'services', 'cashflow', 'plans', 'machine learning']}\n",
            "\n",
            "Cashflow 4Cast Pricing on March 24, 2025 📣 Ready to See If Machine Learning Forecasting Is Right for\n",
            "You? Our ML model learns from your actual sales history to spot patterns and trends a spreadsheet\n",
            "can’t. It works with detailed data — by product, category, or region — and picks up on subtle\n",
            "relationships between items that influence high or low sales. 💡 Want to forecast which products will\n",
            "rise or fall next month? 💡 Curious how a promotion in one category affects others? ML can handle it\n",
            "— and\n",
            "\n",
            "\n",
            "Split into 68 total chunks.\n",
            "Showing first 5 of 68 chunks:\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "Cashflow 4Cast What If You Could Cut Cash Flow Forecasting Errors by 50%? on March 28, 2025 What If\n",
            "You Could Cut Cash Flow Forecasting Errors by 50%? Every business lives or dies by its ability to\n",
            "manage cash flow. Whether it’s covering payroll, restocking inventory, or preparing for a seasonal\n",
            "dip — having reliable numbers makes all the difference. And yet, most small business owners are\n",
            "flying blind with clunky spreadsheets or outdated tools that leave them guessing. That’s where\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "are flying blind with clunky spreadsheets or outdated tools that leave them guessing. That’s where\n",
            "CashFlow4Cast comes in. Using advanced machine learning, we help you cut forecasting errors in half\n",
            "— giving you clearer insight, earlier warnings, and greater confidence in your day-to-day decisions.\n",
            "📉 A Real-World Example Here’s a real forecast from a grocery store chain. First, the Excel-style\n",
            "forecast. Then, our machine learning model. Excel Forecast - Store 4 ML Forecast - Store 4 ⚖️\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "forecast. Then, our machine learning model. Excel Forecast - Store 4 ML Forecast - Store 4 ⚖️\n",
            "Forecasting Accuracy Comparison – Store 1 Model MAE ($) MAPE (%) RMSE ($) Excel 1,395 15.07% 2,083\n",
            "Machine Learning 392 3.59% 522 Metric Definitions: MAE (Mean Absolute Error): The average dollar\n",
            "amount your forecasts were off — lower is better. MAPE (Mean Absolute Percentage Error): The average\n",
            "size of the error as a percentage of actual sales — useful for comparing across stores. RMSE (Root\n",
            "Mean\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "of the error as a percentage of actual sales — useful for comparing across stores. RMSE (Root Mean\n",
            "Squared Error): Similar to MAE, but penalizes large misses more heavily — good for spotting\n",
            "outliers. 50% fewer forecast errors — and in many cases, much more. 📉 Forecasting in Uncertain Times\n",
            "Lately, it’s been harder to plan with confidence. Consumer confidence is down, retail spending has\n",
            "softened, and Gainesville’s unemployment rate is ticking up. Even if your business is steady,\n",
            "uncertainty\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Source: /content/CFFC_docs/CFFC_What If You Could Cut Cash Flow Forecasting Errors by 50%?.txt\n",
            "\n",
            "and Gainesville’s unemployment rate is ticking up. Even if your business is steady, uncertainty can\n",
            "sneak in — and shake up your revenue from month to month. That’s why better forecasting matters. We\n",
            "built a smarter, locally trained machine learning model that helps Gainesville businesses reduce\n",
            "costly forecasting errors — often by 50% or more. Here’s what that means in real dollars: 🧮\n",
            "Spreadsheet-Based Forecasting (Excel or Prophet) Business Type Revenue Low Revenue High Error (%)\n",
            "Error (Low)\n",
            "\n",
            "\n",
            "✅ Stored 68 chunks in Chroma at 'chroma_db'\n",
            "\n",
            "Good afternoon Gainesville business owners,  I am here to brief you on the recent economic\n",
            "indicators in Gainesville that may affect your businesses. Based on the economic documents provided,\n",
            "here are the key trends and their implications for local businesses:  1. Title: \"Gainesville\n",
            "Economic Report - Q3 2021\"    Date: October 15, 2021    Type: Quarterly Report    Tags: GDP,\n",
            "Unemployment, Consumer Spending     Key Trends:    - The GDP of Gainesville has shown a steady\n",
            "growth of 2.5% in the third quarter of 2021.    - Unemployment rate has decreased to 4.2%,\n",
            "indicating a positive trend in the job market.    - Consumer spending has increased by 3% compared\n",
            "to the previous quarter.     Implications:    - With a growing GDP, businesses in Gainesville can\n",
            "expect increased demand for goods and services.    - The declining unemployment rate suggests a\n",
            "larger pool of potential employees for businesses to hire from.    - Higher consumer spending\n",
            "indicates a willingness of customers to make purchases, potentially boosting sales for local\n",
            "businesses.  2. Title: \"Gainesville Business Confidence Survey - Fall 2021\"    Date: November 5,\n",
            "2021    Type: Survey Results    Tags: Business Confidence, Investment Plans, Market Outlook     Key\n",
            "Trends:    - 75% of businesses surveyed expressed confidence in the local economy for the upcoming\n",
            "quarter.    - 60% of businesses plan to increase their investments in the next six months.    - 45%\n",
            "of businesses anticipate an increase in revenue in the next quarter.     Implications:    - High\n",
            "business confidence indicates a positive sentiment among local businesses, which may lead to\n",
            "increased economic activity.    - Increased investment plans suggest a willingness of businesses to\n",
            "expand and grow, potentially creating new opportunities for other businesses in the area.    -\n",
            "Anticipated revenue growth could translate to higher profits and business expansion for local\n",
            "companies.  In conclusion, the recent economic indicators in Gainesville point towards a favorable\n",
            "business climate with growing GDP, declining unemployment, increasing consumer spending, high\n",
            "business confidence, and investment plans. As local business owners, it is essential to capitalize\n",
            "on these trends by expanding operations, hiring new employees, and catering to the rising consumer\n",
            "demand.  Thank you for your attention, and I am available for any further questions or discussions\n",
            "regarding the economic outlook for Gainesville.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You're feeding in **real documents with 2025 dates** via metadata, and yet the model is inventing **fictional documents from 2021** with detailed contents that don’t exist in your corpus. This is a classic case of **hallucination**, and here’s exactly why it's happening — and how to fix or mitigate it:\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 Why It's Still Hallucinating Dates Like \"2021\"\n",
        "\n",
        "Despite your metadata being correct (`\"date\": \"2025-04-02\"` etc.), the model is:\n",
        "\n",
        "1. **Generating fictional documents**\n",
        "   It's not summarizing what’s in your chunks — it's fabricating reports that **sound plausible**, but **don’t exist** in the vectorstore. This means:\n",
        "\n",
        "   * Either the chunks are too small or generic.\n",
        "   * Or the metadata is present but **not emphasized enough** in the prompt or context.\n",
        "   * Or your prompt nudges the model to act like it's reading a report even if it's just guessing.\n",
        "\n",
        "2. **Too little true data per chunk**\n",
        "   You were right earlier: **flattened metadata eats into the chunk size**, which means a 500-character chunk might include 300 characters of metadata and only 200 of document content. This imbalance starves the model of real content and encourages it to guess.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Solutions\n",
        "\n",
        "Here’s what you should do next:\n",
        "\n",
        "#### 1. **Boost chunk size again** (e.g. 750 or even 1000 characters)\n",
        "\n",
        "* Keep overlap at 20%–25% (e.g. 150–200) to preserve continuity.\n",
        "* This will allow full metadata **and** substantial document content to co-exist in a single chunk.\n",
        "\n",
        "#### 2. **Tweak your context formatter to enforce metadata visibility**\n",
        "\n",
        "Right now, the model might skim or ignore the metadata header. Instead, wrap it with clarity:\n",
        "\n",
        "```python\n",
        "\"context\": \"\\n\\n\".join([\n",
        "    f\"[TITLE: {doc.metadata.get('title')}, DATE: {doc.metadata.get('date')}, TYPE: {doc.metadata.get('doc_type')}] \\n{doc.page_content}\"\n",
        "    for doc in d[\"docs\"]\n",
        "])\n",
        "```\n",
        "\n",
        "This makes the metadata stand out and reinforces that it’s meaningful.\n",
        "\n",
        "#### 3. **Anchor the prompt to real documents**\n",
        "\n",
        "In your prompt, you might add a constraint like:\n",
        "\n",
        "```\n",
        "- Do not fabricate new reports; only summarize the information provided in the context.\n",
        "- Refer to documents by title and date as shown.\n",
        "```\n",
        "\n",
        "This tells the model: **\"Don't invent. Use what's in context.\"**\n",
        "\n",
        "#### 4. **Lower temperature slightly**\n",
        "\n",
        "If you're using `temperature=0.4`, you might want to try `0.2` for more grounded, conservative completions.\n",
        "\n",
        "---\n",
        "\n",
        "### Optional Bonus: Add a `source` field to each summary\n",
        "\n",
        "If you want, you can ask the model to **cite which document** each point came from — since you gave it `title`, `date`, and `doc_type`, it could include something like:\n",
        "\n",
        "> \"According to *Gainesville Economic Indicators That Matter to Local Businesses* (April 2, 2025)...\"\n",
        "\n"
      ],
      "metadata": {
        "id": "tPNPYZHUcITC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2B_E0wgwcOhp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}